---
title: "Project"
author: "Trude Almestrand"
date: "8 11 2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Project

### Abstract
### Introduction
Wanting to differentiate between rectum, colon, skin and testis/ovarian cancer
Whether it is rectum or colon cancer plays a big difference treatment wise (https://healthblog.uofmhealth.org/cancer-care/how-colon-and-rectal-cancer-differ)
### Methods
Supervised learning: 
(a) PCA/hierarchal clustering/heatmap to get an initial overview of the data, 
(b) differential expression analysis to reduce the dimensionality, 
(c) machine learning to predict outcome, 
(d) extract some biological insight from the machine learning model
Implement at least two different machine learning methods and use feature selection (differential expression) and cross validation to evaluate them.

Continuing with rectum vs colon cancer in comparisment, 
1.Infer a network for each condition (old and young mice)
2.Construct differential network and matrix
3.Use hieratical clustering to find altered clusters in the differential matrix

*Use log fold change for colon and rectum to compare difference in expression and then analyse and see if we can differentiate them*


### Results
### Discussion
Rectum is technically a part of the colon
### References

http://www.sthda.com/english/articles/37-model-selection-essentials-in-r/152-principal-component-and-partial-least-squares-regression-essentials/ 
https://machinelearningmastery.com/feature-selection-with-real-and-categorical-data/ 
https://www.r-bloggers.com/2014/05/evaluating-model-performance-a-practical-example-of-the-effects-of-overfitting-and-data-size-on-prediction/ 

## Extra

Including code
```{r}
if (!requireNamespace("BiocManager", quietly = TRUE))
  install.packages("BiocManager")
BiocManager::install("TCGAbiolinks")

library(TCGAbiolinks)

# View all projects
# View(TCGAbiolinks:::getGDCprojects())

expr <- data.frame()
samples <- c()
classes <- c()

# Download RNA-Seq data for two selected projects
tissue <- c("Skin", "Testis", "Ovary", "Rectum", "Colon")
proj   <- c("TCGA-SKCM", "TCGA-TGCT", "TCGA-OV", "TCGA-READ", "TCGA-COAD")
for (i in 1:length(proj)) {

  query <- GDCquery(project = proj[i],
                    data.category = "Gene expression",
                    data.type = "Gene expression quantification",
                    platform = "Illumina HiSeq", 
                    file.type = "results",
                    experimental.strategy = "RNA-Seq",
                    legacy = TRUE)
  GDCdownload(query, method = "api", files.per.chunk = 10)
  
  data <- GDCprepare(query, )
  tmp.expr <- assay(data)
  tmp.samples <- paste(tissue[i], colData(data)$primary_diagnosis, sep="-")
  
  # Sample must have 20M reads
  idx <- colSums(tmp.expr) > 20E6
  tmp.expr <- tmp.expr[,idx]
  tmp.samples <- tmp.samples[idx]
  
  # Randomly select 100 samples
  idx <- sample(1:ncol(tmp.expr), 100)
  tmp.expr <- tmp.expr[,idx]
  tmp.samples <- tmp.samples[idx]
  
  if (nrow(expr) == 0) {
    expr <- tmp.expr
  } else {
    expr <- cbind(expr, tmp.expr)
  }
  samples <- c(samples, tmp.samples)
  classes <- c(classes, rep(tissue[i], length(tmp.samples)))
}
remove(tmp.expr, tmp.samples)
classes <- factor(classes)

table(classes)
dim(expr)

# Filtering
# Genes must have 1024 mapped reads in at least 10 samples
expr <- expr[rowSums(expr > 2^10) > 10,]
dim(expr)

save(expr, classes, file = "Project_TCGA.RData")
```

## PCA
```{r}
library(beadarray)
library(DESeq2)

expr <- round(expr)

SampleTable <- data.frame(classes)

# Reads RNA-seq count data
dds <- DESeqDataSetFromMatrix(expr, colData = SampleTable, design = ~classes)

# Sets sample name according to where it was retrieved
colnames(expr) <- classes
#Performs normalization
expr.norm <- varianceStabilizingTransformation(dds)

# Runs PCA
expr.pca <- prcomp(t(assay(expr.norm)))

#Plots PCA
plot(expr.pca$x[, 1], expr.pca$x[, 2], xlab = "PC1", ylab = "PC2", pch = 16, col = classes)
legend("topright", legend = levels(classes), pch = 16, col = 1:5)
```
Now this plot only accounts for 23 and 11.25% of the total variance, we might need to differentiate using clustering in rectum and the colon, see differences in co-expression. 

## Machine learning method
### KNN
```{r}
library(class)

n <- nrow(t(assay(expr.norm))) # Selects rows of transformed expr.norm (containing samples)
selected.rows <- split(sample(n), rep(c("train","test"), length = n)) # Splits rows randomly into test and training

expr.classes <- rownames(t(assay(expr.norm))) # Retrieves sample names for saving

expr.unlabelled <- t(assay(expr.norm)) # Fetches data and labels samples as null 
rownames(expr.unlabelled)<- NULL

expr.train <- expr.unlabelled[selected.rows$train,] #Makes training data
expr.test <- expr.unlabelled[selected.rows$test, ] # makes testdata

expr.knn <- knn(expr.train, expr.test, classes[selected.rows$train], k = 4) # Runs KNN with 4 neighbors
expr.knn.cv <- knn.cv(expr.unlabelled, classes, k=4) # Runs knn with cross validation
knn_table <- table(classes, expr.knn.cv, dnn = c("Real", "Predicted"))

# Calculate accuracy of method
knn_table
accuracy_knn <- sum(diag(knn_table))/ sum(knn_table)
accuracy_knn
```
#### ROC kurve true positives vs false positive rate
```{r}

```


### SVM

```{r}
library(e1071)

# Trains model using training data
svm.model <- svm(expr.train, classes[selected.rows$train])

# Predict classes for test data
svm.pred <- predict(svm.model, expr.test)

# Create a confusion matrix
confusion <- table(classes[selected.rows$test], svm.pred, dnn = c("Real", "Predicted"))
confusion

# Measure accuracy of method
accuracy <- sum(diag(confusion))/ sum(confusion)

accuracy

## Now for training our SVM model:

# Start by getting the indices for all possible test sets
nsets <- 10 # The number of sets of different training/test data we want to use for cross validation
n <- nrow(expr.unlabelled) # The number of samples in the iris data
cv.sets <- split(sample(n), rep(seq_len(nsets), length = n)) # Create 10 different random sets of sample row numbers

accuracies <- NULL
# Iterate through the different sets of row numbers...
for (set in cv.sets) {
  # The current row numbers (`set`) corresponds to the test data, so
  # for training, we use `-set` to use all samples but the test samples.
  svm.model <- svm(expr.unlabelled[-set, ], classes[-set])
  svm.pred <- predict(svm.model, expr.unlabelled[set, ])
  confusion <- table(classes[set], svm.pred)
  # Calculate current accuracy, and add to the list of accuracies
  accuracies <- c(accuracies, sum(diag(confusion)) / sum(confusion)) 
}
# Calculate the mean accuracy from the 10 tests
mean_accuracy <- mean(accuracies)
mean_accuracy


```
#### ROC kurve true positives vs false positive rate 

#### Grid search with SVM for data

```{r}
C <- c(0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000)
gamma <- c(0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000)

# Get all combinations of C and gamma with the `expand.grid` function.
# It will return a data frame with the combinations, and that we then
# `cbind` with an empty accuracy vector that we will fill in the
# grid search.
acc.df <- cbind(expand.grid(C = C, gamma = gamma), accuracy = NA)

# For each C and gamma, find the accuracy of the model and add it to
# the data frame.
for (i in seq_len(nrow(acc.df))) {
  svm.model <- svm(expr.train, classes[selected.rows$train], cost = acc.df[i, "C"], gamma = acc.df[i, "gamma"])
  svm.pred <- predict(svm.model, expr.test)
  confusion <- table(classes[selected.rows$test], svm.pred)
  acc.df$accuracy[i] <- sum(diag(confusion)) / sum(confusion)
}

# Plot contours of accuracies for different C and gamma values
library(ggplot2)
library(directlabels)
accuracy.contour <- ggplot(acc.df, aes(C, gamma, z = accuracy)) +
  stat_contour(aes(colour = ..level..), binwidth = 0.15) +
  scale_colour_gradient(low = "tomato", high = "forestgreen") +
  scale_x_log10("C") + scale_y_log10(bquote(gamma)) + theme_bw()
direct.label(accuracy.contour, "top.pieces")
```
For this data set it would be wise to have 
#### ROC kurve true positives vs false positive rate



## Differential expression with adjustes p-value < 0.05
```{r}
# DEG analysis based on negative binomial distribution
test <- DESeq(dds)

# Retrieve base mean across samples
res <- results(test)

# Do test statistic to reduce dimensionality - we only want genes that contribute here in testis v ovary
res0.05 <- subset(res, padj < 0.05)
```


## PCA compared to PLS

```{r}
library(tidyverse)
library(caret)
library(pls)

n <- nrow(t(assay(expr.norm))) # Selects rows of transformed expr.norm (containing samples)
selected.rows <- split(sample(n), rep(c("train","test"), length = n)) # Splits rows randomly into test and training

expr.classes <- rownames(t(assay(expr.norm))) # Retrieves sample names for saving

expr.unlabelled <- t(assay(expr.norm)) # Fetches data and labels samples as null 
rownames(expr.unlabelled)<- NULL

expr.train <- expr.unlabelled[selected.rows$train,] #Makes training data
expr.test <- expr.unlabelled[selected.rows$test, ] # makes testdata

# Build the model on training set
model <- train(
  expr.train, method = "pcr",
  scale = TRUE,
  trControl = trainControl("cv", number = 10),
  tuneLength = 10
  )
# Plot model RMSE vs different values of components
plot(model)
# Print the best tuning parameter ncomp that
# minimize the cross-validation error, RMSE
model$bestTune

```

### Use only rectum and colon data

```{r}
if (!requireNamespace("BiocManager", quietly = TRUE))
  install.packages("BiocManager")
BiocManager::install("TCGAbiolinks")

library(TCGAbiolinks)

# View all projects
# View(TCGAbiolinks:::getGDCprojects())

expr <- data.frame()
samples <- c()
classes <- c()

# Download RNA-Seq data for two selected projects
tissue <- c( "Rectum", "Colon")
proj   <- c("TCGA-READ", "TCGA-COAD")
for (i in 1:length(proj)) {

  query <- GDCquery(project = proj[i],
                    data.category = "Gene expression",
                    data.type = "Gene expression quantification",
                    platform = "Illumina HiSeq", 
                    file.type = "results",
                    experimental.strategy = "RNA-Seq",
                    legacy = TRUE)
  GDCdownload(query, method = "api", files.per.chunk = 10)
  
  data <- GDCprepare(query, )
  tmp.expr <- assay(data)
  tmp.samples <- paste(tissue[i], colData(data)$primary_diagnosis, sep="-")
  
  # Sample must have 20M reads
  idx <- colSums(tmp.expr) > 20E6
  tmp.expr <- tmp.expr[,idx]
  tmp.samples <- tmp.samples[idx]
  
  # Randomly select 100 samples
  idx <- sample(1:ncol(tmp.expr), 100)
  tmp.expr <- tmp.expr[,idx]
  tmp.samples <- tmp.samples[idx]
  
  if (nrow(expr) == 0) {
    expr <- tmp.expr
  } else {
    expr <- cbind(expr, tmp.expr)
  }
  samples <- c(samples, tmp.samples)
  classes <- c(classes, rep(tissue[i], length(tmp.samples)))
}
remove(tmp.expr, tmp.samples)
classes2 <- factor(classes)

table(classes)
dim(expr)

# Filtering
# Genes must have 1024 mapped reads in at least 10 samples
expr2 <- expr[rowSums(expr > 2^10) > 10,]
dim(expr2)

save(expr2, classes2, file = "Project_TCGA_Rectum_and_Colon.RData")
```



```{r}
library(beadarray)
library(DESeq2)

expr2 <- round(expr2)

SampleTable <- data.frame(classes2)

# Reads RNA-seq count data
dds2 <- DESeqDataSetFromMatrix(expr2, colData = SampleTable, design = ~classes2)

# Sets sample name according to where it was retrieved
colnames(expr2) <- classes2
#Performs normalization
expr.norm2 <- varianceStabilizingTransformation(dds2)

# Runs PCA
expr.pca2 <- prcomp(t(assay(expr.norm2)))

#Plots PCA
plot(expr.pca2$x[, 1], expr.pca2$x[, 2], xlab = "PC1", ylab = "PC2", pch = 16, col = classes2)
legend("topright", legend = levels(classes2), pch = 16, col = 1:5)
```


## Gene set enrichment analysis
```{r}


```
